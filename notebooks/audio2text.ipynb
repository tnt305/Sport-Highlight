{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Read CSV file\n",
    "audio_list = pd.read_csv(\"dataset2.csv\", sep=\";\")\n",
    "audio_list = audio_list['audio_id'].tolist()\n",
    "\n",
    "# Save as JSON\n",
    "with open(\"audio_list.json\", \"w\") as f:\n",
    "    json.dump(audio_list, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"audio_list.json\", \"r\") as f:\n",
    "    audio_list = json.load(f)\n",
    "    \n",
    "audio_list = audio_list[2606:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:02<00:00, 149.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "base_dir = \"F:/video_classification\"\n",
    "video_dir = [f\"{base_dir}/{i}\" for i in os.listdir(base_dir)]\n",
    "\n",
    "audio_list = []\n",
    "for item in tqdm(video_dir):#video_dir:\n",
    "    chunk_dir = [f\"{item}/{i}\" for i in os.listdir(item) if os.path.isdir(f\"{item}/{i}\")]\n",
    "    for chunk in chunk_dir:\n",
    "        audio_dir = [f\"{chunk}/{i}\" for i in os.listdir(chunk) if i.startswith(\"video\")]\n",
    "        audio_list.append(audio_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 341.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total audio files: 27414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import itertools\n",
    "\n",
    "base_dir = \"F:/video_classification\"\n",
    "\n",
    "# Dùng os.scandir() để tăng tốc duyệt thư mục\n",
    "video_dirs = [entry.path for entry in os.scandir(base_dir) if entry.is_dir()]\n",
    "\n",
    "def process_chunk_dir(item):\n",
    "    \"\"\"Xử lý từng thư mục chunk, trả về danh sách audio file\"\"\"\n",
    "    chunk_dirs = [entry.path for entry in os.scandir(item) if entry.is_dir()]\n",
    "    audio_files = list(itertools.chain.from_iterable(\n",
    "        [[f\"{chunk}/{i}\" for i in os.listdir(chunk) if i.startswith(\"video\")]\n",
    "         for chunk in chunk_dirs]\n",
    "    ))\n",
    "    return audio_files\n",
    "\n",
    "# Sử dụng ThreadPoolExecutor để đa luồng\n",
    "audio_list = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    results = list(tqdm(executor.map(process_chunk_dir, video_dirs), total=len(video_dirs)))\n",
    "\n",
    "# Flatten danh sách kết quả\n",
    "audio_list = list(itertools.chain.from_iterable(results))\n",
    "\n",
    "print(f\"Total audio files: {len(audio_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "# Path to your JSON file\n",
    "json_file_path = \"D:\\\\projects\\\\v2v\\\\v5\\\\audio_list.json\"\n",
    "\n",
    "# Open and load JSON file\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    file_paths = json.load(f)  # Convert JSON to Python object (dict or list)\n",
    "\n",
    "# Nhóm video theo trận đấu\n",
    "video_groups = defaultdict(list)\n",
    "\n",
    "for path in file_paths:\n",
    "    match = re.search(r'video_classification/(.*?)/chunk_\\d+', path)\n",
    "    if match:\n",
    "        match_key = match.group(1)  # Lấy phần \"2014-11-04 - 22-45 Arsenal 3 - 3 Anderlecht\"\n",
    "        video_groups[match_key].append(path)\n",
    "\n",
    "# Hàm trích xuất số chunk để sắp xếp\n",
    "def extract_chunk_number(path):\n",
    "    match = re.search(r'chunk_(\\d+)', path)\n",
    "    return int(match.group(1)) if match else float('inf')\n",
    "\n",
    "# Sắp xếp theo trận đấu và số chunk\n",
    "sorted_videos = []\n",
    "for match_key in sorted(video_groups.keys()):  # Sắp xếp theo trận đấu trước\n",
    "    sorted_videos.extend(sorted(video_groups[match_key], key=extract_chunk_number))\n",
    "\n",
    "# In kết quả\n",
    "# print(\"\\n\".join(sorted_videos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_videos = sorted_videos[13196:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27414/27414 [00:00<00:00, 197269.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path \n",
    "def normalize_path(path: str):\n",
    "    return Path(path).as_posix()\n",
    "\n",
    "audio_lists = []\n",
    "for item in tqdm(audio_list):\n",
    "    audio_lists.append(normalize_path(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Danh sách audio đã được lưu vào: audio_list.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Đường dẫn lưu tệp JSON\n",
    "json_file_path = \"audio_list.json\"\n",
    "\n",
    "# Ghi danh sách vào tệp JSON\n",
    "with open(json_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(audio_lists, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Danh sách audio đã được lưu vào: {json_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "audio_list = pandas.read_csv(\"dataset2.csv\", sep = \";\")\n",
    "audio_list = audio_list['audio_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zul_Latn'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANGUAGE_CODE = {\n",
    "    'ace': 'ace_Latn',\n",
    "    'ar': 'arz_Arab',\n",
    "    'af': 'afr_Latn',\n",
    "    'ak': 'aka_Latn',\n",
    "    'am': 'amh_Ethi',\n",
    "    'as': 'asm_Beng',\n",
    "    'ast': 'ast_Latn',\n",
    "    'awa': 'awa_Deva',\n",
    "    'ay': 'ayr_Latn',\n",
    "    'az': 'azj_Latn',\n",
    "    'ba': 'bak_Cyrl',\n",
    "    'bm': 'bam_Latn',\n",
    "    'ban': 'ban_Latn',\n",
    "    'be': 'bel_Cyrl',\n",
    "    'bem': 'bem_Latn',\n",
    "    'bn': 'ben_Beng',\n",
    "    'bho': 'bho_Deva',\n",
    "    'bjn': 'bjn_Latn',\n",
    "    'bo': 'bod_Tibt',\n",
    "    'bs': 'bos_Latn',\n",
    "    'bug': 'bug_Latn',\n",
    "    'bg': 'bul_Cyrl',\n",
    "    'ca': 'cat_Latn',\n",
    "    'ceb': 'ceb_Latn',\n",
    "    'cs': 'ces_Latn',\n",
    "    'cjk': 'cjk_Latn',\n",
    "    'ckb': 'ckb_Arab',\n",
    "    'crh': 'crh_Latn',\n",
    "    'cy': 'cym_Latn',\n",
    "    'da': 'dan_Latn',\n",
    "    'de': 'deu_Latn',\n",
    "    'dik': 'dik_Latn',\n",
    "    'dyu': 'dyu_Latn',\n",
    "    'dz': 'dzo_Tibt',\n",
    "    'el': 'ell_Grek',\n",
    "    'en': 'eng_Latn',\n",
    "    'eo': 'epo_Latn',\n",
    "    'et': 'est_Latn',\n",
    "    'eu': 'eus_Latn',\n",
    "    'ewe': 'ewe_Latn',\n",
    "    'fo': 'fao_Latn',\n",
    "    'fa': 'pes_Arab',\n",
    "    'fij': 'fij_Latn',\n",
    "    'fi': 'fin_Latn',\n",
    "    'fon': 'fon_Latn',\n",
    "    'fr': 'fra_Latn',\n",
    "    'fur': 'fur_Latn',\n",
    "    'fuv': 'fuv_Latn',\n",
    "    'gd': 'gla_Latn',\n",
    "    'ga': 'gle_Latn',\n",
    "    'gl': 'glg_Latn',\n",
    "    'gn': 'grn_Latn',\n",
    "    'gu': 'guj_Gujr',\n",
    "    'ht': 'hat_Latn',\n",
    "    'ha': 'hau_Latn',\n",
    "    'he': 'heb_Hebr',\n",
    "    'hi': 'hin_Deva',\n",
    "    'hne': 'hne_Deva',\n",
    "    'hr': 'hrv_Latn',\n",
    "    'hu': 'hun_Latn',\n",
    "    'hy': 'hye_Armn',\n",
    "    'ig': 'ibo_Latn',\n",
    "    'ilo': 'ilo_Latn',\n",
    "    'id': 'ind_Latn',\n",
    "    'is': 'isl_Latn',\n",
    "    'it': 'ita_Latn',\n",
    "    'jv': 'jav_Latn',\n",
    "    'ja': 'jpn_Jpan',\n",
    "    'kab': 'kab_Latn',\n",
    "    'kac': 'kac_Latn',\n",
    "    'kam': 'kam_Latn',\n",
    "    'kn': 'kan_Knda',\n",
    "    'ks': 'kas_Deva',\n",
    "    'ka': 'kat_Geor',\n",
    "    'knc': 'knc_Latn',\n",
    "    'kk': 'kaz_Cyrl',\n",
    "    'kbp': 'kbp_Latn',\n",
    "    'kea': 'kea_Latn',\n",
    "    'km': 'khm_Khmr',\n",
    "    'ki': 'kik_Latn',\n",
    "    'rw': 'kin_Latn',\n",
    "    'ky': 'kir_Cyrl',\n",
    "    'kmb': 'kmb_Latn',\n",
    "    'kon': 'kon_Latn',\n",
    "    'ko': 'kor_Hang',\n",
    "    'kmr': 'kmr_Latn',\n",
    "    'lo': 'lao_Laoo',\n",
    "    'lv': 'lvs_Latn',\n",
    "    'lij': 'lij_Latn',\n",
    "    'li': 'lim_Latn',\n",
    "    'ln': 'lin_Latn',\n",
    "    'lt': 'lit_Latn',\n",
    "    'lmo': 'lmo_Latn',\n",
    "    'ltg': 'ltg_Latn',\n",
    "    'lb': 'ltz_Latn',\n",
    "    'lua': 'lua_Latn',\n",
    "    'lg': 'lug_Latn',\n",
    "    'luo': 'luo_Latn',\n",
    "    'lus': 'lus_Latn',\n",
    "    'mag': 'mag_Deva',\n",
    "    'mai': 'mai_Deva',\n",
    "    'ml': 'mal_Mlym',\n",
    "    'mr': 'mar_Deva',\n",
    "    'min': 'min_Latn',\n",
    "    'mk': 'mkd_Cyrl',\n",
    "    'plt': 'plt_Latn',\n",
    "    'mt': 'mlt_Latn',\n",
    "    'mni': 'mni_Beng',\n",
    "    'khk': 'khk_Cyrl',\n",
    "    'mos': 'mos_Latn',\n",
    "    'mi': 'mri_Latn',\n",
    "    'ms': 'zsm_Latn',\n",
    "    'my': 'mya_Mymr',\n",
    "    'nl': 'nld_Latn',\n",
    "    'nn': 'nno_Latn',\n",
    "    'nb': 'nob_Latn',\n",
    "    'np': 'npi_Deva',\n",
    "    'nso': 'nso_Latn',\n",
    "    'nus': 'nus_Latn',\n",
    "    'ny': 'nya_Latn',\n",
    "    'oc': 'oci_Latn',\n",
    "    'gaz': 'gaz_Latn',\n",
    "    'or': 'ory_Orya',\n",
    "    'pag': 'pag_Latn',\n",
    "    'pa': 'pan_Guru',\n",
    "    'pap': 'pap_Latn',\n",
    "    'pl': 'pol_Latn',\n",
    "    'pt': 'por_Latn',\n",
    "    'prs': 'prs_Arab',\n",
    "    'pbt': 'pbt_Arab',\n",
    "    'quy': 'quy_Latn',\n",
    "    'ro': 'ron_Latn',\n",
    "    'rn': 'run_Latn',\n",
    "    'ru': 'rus_Cyrl',\n",
    "    'sag': 'sag_Latn',\n",
    "    'sa': 'san_Deva',\n",
    "    'sat': 'sat_Beng',\n",
    "    'scn': 'scn_Latn',\n",
    "    'shn': 'shn_Mymr',\n",
    "    'si': 'sin_Sinh',\n",
    "    'sk': 'slk_Latn',\n",
    "    'sl': 'slv_Latn',\n",
    "    'sm': 'smo_Latn',\n",
    "    'sn': 'sna_Latn',\n",
    "    'sd': 'snd_Arab',\n",
    "    'so': 'som_Latn',\n",
    "    'st': 'sot_Latn',\n",
    "    'es': 'spa_Latn',\n",
    "    'sq': 'als_Latn',\n",
    "    'sc': 'srd_Latn',\n",
    "    'sr': 'srp_Cyrl',\n",
    "    'ss': 'ssw_Latn',\n",
    "    'su': 'sun_Latn',\n",
    "    'sv': 'swe_Latn',\n",
    "    'sw': 'swh_Latn',\n",
    "    'szl': 'szl_Latn',\n",
    "    'ta': 'tam_Taml',\n",
    "    'tt': 'tat_Cyrl',\n",
    "    'te': 'tel_Telu',\n",
    "    'tg': 'tgk_Cyrl',\n",
    "    'tl': 'tgl_Latn',\n",
    "    'th': 'tha_Thai',\n",
    "    'ti': 'tir_Ethi',\n",
    "    'taq': 'taq_Tfng',\n",
    "    'tpi': 'tpi_Latn',\n",
    "    'tsn': 'tsn_Latn',\n",
    "    'tso': 'tso_Latn',\n",
    "    'tk': 'tuk_Latn',\n",
    "    'tum': 'tum_Latn',\n",
    "    'tr': 'tur_Latn',\n",
    "    'tw': 'twi_Latn',\n",
    "    'tzm': 'tzm_Tfng',\n",
    "    'ug': 'uig_Arab',\n",
    "    'uk': 'ukr_Cyrl',\n",
    "    'umb': 'umb_Latn',\n",
    "    'ur': 'urd_Arab',\n",
    "    'uz': 'uzn_Latn',\n",
    "    'vec': 'vec_Latn',\n",
    "    'vi': 'vie_Latn',\n",
    "    'war': 'war_Latn',\n",
    "    'wo': 'wol_Latn',\n",
    "    'xh': 'xho_Latn',\n",
    "    'yid': 'ydd_Hebr',\n",
    "    'yo': 'yor_Latn',\n",
    "    'yue': 'yue_Hant',\n",
    "    'zh': 'zho_Hant',\n",
    "    'zu': 'zul_Latn'}\n",
    "\n",
    "LANGUAGE_CODE.get('zu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\v2v\\v5\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from typing import Optional, List\n",
    "from faster_whisper import WhisperModel\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def process_file_with_run(args):\n",
    "    \"\"\"\n",
    "    Hàm độc lập để xử lý một file âm thanh sử dụng phương thức run()\n",
    "    \"\"\"\n",
    "    audio_path, config = args\n",
    "    \n",
    "    # Tạo một instance Audio2Text mới với file đầu ra tạm thời\n",
    "    processor = Audio2Text(\n",
    "        stt_model_name=config['stt_model_name'],\n",
    "        translate_model_name=config['translate_model_name'],\n",
    "        max_text_gen=config['max_text_gen'],\n",
    "        idx=config['idx'],\n",
    "        device=config['device'],\n",
    "        cpu_threads=config['cpu_threads'],\n",
    "        compute_type=config['compute_type'],\n",
    "        src_lang=config['src_lang'],\n",
    "        target_lang=config['target_lang'],\n",
    "        json_output_dir=config['temp_output_dir']\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Xử lý file và lưu vào file tạm\n",
    "        result = processor.run(audio_path)\n",
    "        return {\n",
    "            'success': True,\n",
    "            'result': result,\n",
    "            'audio_path': audio_path\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': str(e),\n",
    "            'audio_path': audio_path\n",
    "        }\n",
    "class Audio2Text:\n",
    "    def __init__(self, \n",
    "                 stt_model_name: str = 'distil-large-v3',\n",
    "                 translate_model_name: str = \"Emilio407/nllb-200-3.3B-8bit\", #\"facebook/nllb-200-3.3B\",\n",
    "                 max_text_gen: int = 625,\n",
    "                 idx: int = 0,\n",
    "                 device: Optional[str] = None,\n",
    "                 cpu_threads: int = 4,\n",
    "                 compute_type: str = 'int8_float16',\n",
    "                 src_lang: str = None,\n",
    "                 target_lang: str = 'eng_Latn',\n",
    "                 json_output_dir: str = 'translated_audio2text.jsonl'):\n",
    "        super(Audio2Text, self).__init__()\n",
    "        self.stt_model_name = stt_model_name\n",
    "        self.translate_model_name = translate_model_name\n",
    "        self.max_text_gen = max_text_gen\n",
    "        \n",
    "        self.idx = idx\n",
    "        \n",
    "        if device is None:\n",
    "            os.environ['CUDA_VISIBLE_DEVICES'] = str(self.idx)\n",
    "            self.device = f'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "        self.cpu_threads = cpu_threads\n",
    "        self.compute_type = compute_type\n",
    "        self.json_output_dir = json_output_dir\n",
    "        \n",
    "        # Khởi tạo mô hình faster-whisper\n",
    "        if self.stt_model_name is not None:\n",
    "            self.stt_model = WhisperModel(model_size_or_path = self.stt_model_name, \n",
    "                             device=self.device,\n",
    "                             device_index= self.idx, \n",
    "                             cpu_threads=self.cpu_threads,\n",
    "                             compute_type=self.compute_type,\n",
    "                             )\n",
    "        else:\n",
    "            raise Exception(\"Model For Speech To text not found. Please add a valid model name.\")\n",
    "        \n",
    "        # khởi tạo mô hình dịch\n",
    "        if self.translate_model_name is not None:\n",
    "            self.translate_model = AutoModelForSeq2SeqLM.from_pretrained(self.translate_model_name)\n",
    "            self.translate_tokenizer = AutoTokenizer.from_pretrained(self.translate_model_name)\n",
    "        else:\n",
    "            raise Exception(\"Model for Translation not found. Please add a valid model name.\")\n",
    "        \n",
    "        self.src_lang = src_lang \n",
    "        self.target_lang = target_lang\n",
    "        self.translator = None\n",
    "        \n",
    "        # Chỉ khởi tạo translator nếu src_lang đã được xác định\n",
    "        if self.src_lang is not None:\n",
    "            self.create_translator(self.src_lang, self.target_lang)\n",
    "    \n",
    "    def create_translator(self, src_lang, tgt_lang):\n",
    "        \"\"\"\n",
    "        Tạo hoặc cập nhật translator với ngôn ngữ nguồn và đích chỉ định\n",
    "        \"\"\"\n",
    "        self.translator = pipeline('translation', \n",
    "                            model=self.translate_model_name, \n",
    "                            tokenizer=self.translate_tokenizer, \n",
    "                            src_lang=src_lang, \n",
    "                            tgt_lang=tgt_lang, \n",
    "                            device=self.idx,\n",
    "                            max_length=self.max_text_gen,\n",
    "                            use_fast=True)\n",
    "        return self.translator\n",
    "    \n",
    "    @staticmethod\n",
    "    def remove_sentence_with_phrase(text, phrase):\n",
    "        sentences = text.split('.')\n",
    "        filtered_sentences = [sentence.strip() for sentence in sentences if phrase.lower() not in sentence.lower()]\n",
    "        filtered_sentences =  '. '.join(filtered_sentences) + ('' if len(filtered_sentences) > 0 else '')\n",
    "        return filtered_sentences.strip()\n",
    "    \n",
    "    @staticmethod\n",
    "    def postprocess_translation(text: str):\n",
    "        text = text.replace(\"  \", \" \")\n",
    "        text = text.replace(\"No.\", \"the number\")\n",
    "        text = Audio2Text.remove_sentence_with_phrase(text, \"Please subcribe\")\n",
    "        text = text.replace(\"  \", \" \")\n",
    "        text = text.replace(\". . .\", \".\")\n",
    "        text = text.replace (\"...\", \".\")\n",
    "        return text\n",
    "        \n",
    "    def transcribe(self, audio_path):\n",
    "        segments, info = self.stt_model.transcribe(audio_path, multilingual= True,\n",
    "                                                beam_size= 3,\n",
    "                                                no_speech_threshold = 1.0, \n",
    "                                                hotwords =\"pressure, penalty, strike, shot, pass, foul, offside, corner kick, save, clearance, counter\",\n",
    "                                                vad_filter = True,\n",
    "                                                vad_parameters=dict(min_silence_duration_ms=1000))\n",
    "        text = \" \".join([segment.text for segment in segments])\n",
    "        text = text.replace(\"  \", \" \")\n",
    "        return text, info.language, info.language_probability\n",
    "    \n",
    "    def __google_translate(self, text):\n",
    "        translator = GoogleTranslator(source=\"auto\", target=\"en\")\n",
    "        text = translator.translate(text)\n",
    "        text = Audio2Text.postprocess_translation(text)\n",
    "        return text.replace(\"  \", \" \")\n",
    "    \n",
    "    def save_to_jsonl(self, result_dict):\n",
    "        \"\"\"\n",
    "        Save translation result to JSONL file (JSON Lines)\n",
    "        Each result is written as a separate line in the file\n",
    "        \"\"\"\n",
    "        # Append new result as a new line\n",
    "        with open(self.json_output_dir, 'a', encoding='utf-8') as f:\n",
    "            # If the file is new/empty, no need for a newline at the beginning\n",
    "            if os.path.getsize(self.json_output_dir) > 0:\n",
    "                f.write('\\n')\n",
    "            f.write(json.dumps(result_dict, ensure_ascii=False))\n",
    "    \n",
    "    def translation(self, audio_path: str):\n",
    "        \"\"\"\n",
    "        - Đầu tiên sử dụng transcribe của fasterwhisper để dịch\n",
    "        - Check xem language là gì, để convert sang tiếng anh\n",
    "        - Nếu language không phải là tiếng anh:\n",
    "            - thực hiện translation và nếu translation bị none thì sử dụng google translatetranslate\n",
    "        \"\"\"\n",
    "        \n",
    "        text, lang, lang_prob = self.transcribe(audio_path)\n",
    "        origin_text = text\n",
    "        translation_type = \"no_translation\"\n",
    "        translated_text = text\n",
    "\n",
    "        if lang != 'en' or lang_prob <= 0.8:\n",
    "            detected_src_lang = None\n",
    "            \n",
    "            # Xác định ngôn ngữ nguồn\n",
    "            if self.src_lang is None:\n",
    "                try:\n",
    "                    detected_src_lang = LANGUAGE_CODE.get(lang)\n",
    "                    if detected_src_lang is None:\n",
    "                        # Không tìm thấy mã ngôn ngữ, dùng Google Translate\n",
    "                        translated_text = self.__google_translate(text)\n",
    "                        translation_type = \"deep\"\n",
    "                        return {\n",
    "                            \"audio_path\": audio_path,\n",
    "                            \"translation_type\": translation_type,\n",
    "                            \"origin\": origin_text,\n",
    "                            \"translation\": translated_text\n",
    "                        }\n",
    "                except Exception:\n",
    "                    # Lỗi khi xác định ngôn ngữ, dùng Google Translate\n",
    "                    translated_text = self.__google_translate(text)\n",
    "                    translation_type = \"deep\"\n",
    "                    return {\n",
    "                        \"audio_path\": audio_path,\n",
    "                        \"translation_type\": translation_type,\n",
    "                        \"origin\": origin_text,\n",
    "                        \"translation\": translated_text\n",
    "                    }\n",
    "            else:\n",
    "                detected_src_lang = self.src_lang\n",
    "            \n",
    "            try:\n",
    "                # Tạo translator nếu cần\n",
    "                if self.translator is None or (detected_src_lang and detected_src_lang != self.src_lang):\n",
    "                    self.create_translator(detected_src_lang, self.target_lang)\n",
    "                \n",
    "                # Dịch văn bản\n",
    "                result = self.translator(text)\n",
    "                translated_text = result[0]['translation_text']\n",
    "                translation_type = \"nlln\"\n",
    "                \n",
    "                if translated_text is None or translated_text == \" \" or translated_text == \"\":\n",
    "                    translated_text = self.__google_translate(text)\n",
    "                    translation_type = \"deep\"\n",
    "            except Exception:\n",
    "                # Fallback to Google Translate if any error occurs\n",
    "                translated_text = self.__google_translate(text)\n",
    "                translation_type = \"deep\"\n",
    "        \n",
    "        result = {\n",
    "            \"audio_path\": audio_path,\n",
    "            \"translation_type\": translation_type, \n",
    "            \"origin\": origin_text,\n",
    "            \"translation\": translated_text\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    def run(self, audio_path: str,):\n",
    "        \"\"\"\n",
    "        Complete process: transcribe, translate, and save results to JSON in one step\n",
    "        \n",
    "        Args:\n",
    "            src_lang: Source language code (optional)\n",
    "            target_lang: Target language code, defaults to 'eng_Latn'\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing translation results\n",
    "        \"\"\"\n",
    "        # Get translation results\n",
    "        result = self.translation(audio_path = audio_path)\n",
    "        \n",
    "        # Save results to JSON\n",
    "        self.save_to_jsonl(result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def batch_translation(self, texts: List[str], langs: List[str], audio_paths: List[str]):\n",
    "        \"\"\"\n",
    "        Dịch nhiều văn bản cùng lúc để tận dụng khả năng xử lý batch của GPU\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # Xác định các văn bản cần dịch (không phải tiếng Anh)\n",
    "        texts_by_lang = {}  # Nhóm văn bản theo ngôn ngữ\n",
    "        \n",
    "        for i, (text, lang, path) in enumerate(zip(texts, langs, audio_paths)):\n",
    "            if lang == 'en':\n",
    "                # Không cần dịch văn bản tiếng Anh\n",
    "                results.append({\n",
    "                    \"audio_path\": path,\n",
    "                    \"translation_type\": \"no_translation\",\n",
    "                    \"origin\": text,\n",
    "                    \"translation\": text\n",
    "                })\n",
    "            else:\n",
    "                # Xác định mã ngôn ngữ nguồn\n",
    "                try:\n",
    "                    src_lang_code = self.src_lang if self.src_lang else LANGUAGE_CODE.get(lang)\n",
    "                    \n",
    "                    if src_lang_code:\n",
    "                        # Nhóm theo ngôn ngữ\n",
    "                        if src_lang_code not in texts_by_lang:\n",
    "                            texts_by_lang[src_lang_code] = []\n",
    "                        \n",
    "                        texts_by_lang[src_lang_code].append({\n",
    "                            \"index\": i,\n",
    "                            \"text\": text,\n",
    "                            \"path\": path\n",
    "                        })\n",
    "                    else:\n",
    "                        # Không tìm thấy mã ngôn ngữ, dùng Google Translate\n",
    "                        translated = self.__google_translate(text)\n",
    "                        results.append({\n",
    "                            \"audio_path\": path,\n",
    "                            \"translation_type\": \"deep\",\n",
    "                            \"origin\": text,\n",
    "                            \"translation\": translated\n",
    "                        })\n",
    "                except Exception:\n",
    "                    # Xử lý lỗi, dùng Google Translate\n",
    "                    translated = self.__google_translate(text)\n",
    "                    results.append({\n",
    "                        \"audio_path\": path,\n",
    "                        \"translation_type\": \"deep\",\n",
    "                        \"origin\": text,\n",
    "                        \"translation\": translated\n",
    "                    })\n",
    "        \n",
    "        # Xử lý dịch theo từng ngôn ngữ\n",
    "        for src_lang_code, text_group in texts_by_lang.items():\n",
    "            try:\n",
    "                # Tạo translator cho ngôn ngữ này\n",
    "                translator = self.create_translator(src_lang_code, self.target_lang)\n",
    "                \n",
    "                # Chuẩn bị văn bản để dịch\n",
    "                texts_to_translate = [item[\"text\"] for item in text_group]\n",
    "                \n",
    "                # Dịch cả batch\n",
    "                translated_batch = translator(texts_to_translate)\n",
    "                \n",
    "                # Xử lý kết quả\n",
    "                for i, (item, translated) in enumerate(zip(text_group, translated_batch)):\n",
    "                    translated_text = translated[\"translation_text\"]\n",
    "                    \n",
    "                    if not translated_text or translated_text.strip() == \"\":\n",
    "                        # Fallback to Google Translate\n",
    "                        translated_text = self.__google_translate(item[\"text\"])\n",
    "                        translation_type = \"deep\"\n",
    "                    else:\n",
    "                        translation_type = \"nlln\"\n",
    "                    \n",
    "                    results.append({\n",
    "                        \"audio_path\": item[\"path\"],\n",
    "                        \"translation_type\": translation_type,\n",
    "                        \"origin\": item[\"text\"],\n",
    "                        \"translation\": translated_text\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi dịch batch ngôn ngữ {src_lang_code}: {str(e)}\")\n",
    "                # Dùng Google Translate cho từng văn bản\n",
    "                for item in text_group:\n",
    "                    translated = self.__google_translate(item[\"text\"])\n",
    "                    results.append({\n",
    "                        \"audio_path\": item[\"path\"],\n",
    "                        \"translation_type\": \"deep\",\n",
    "                        \"origin\": item[\"text\"],\n",
    "                        \"translation\": translated\n",
    "                    })\n",
    "        \n",
    "        # Sắp xếp kết quả theo thứ tự ban đầu (nếu cần)\n",
    "        # results.sort(key=lambda x: audio_paths.index(x[\"audio_path\"]))\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def improved_batch_run(self, audio_paths: List[str], batch_size: int = 16):\n",
    "        \"\"\"\n",
    "        Phiên bản cải tiến xử lý batch, tận dụng tối đa GPU\n",
    "        \n",
    "        Args:\n",
    "            audio_paths: Danh sách đường dẫn các file âm thanh\n",
    "            batch_size: Số lượng file xử lý trong mỗi batch\n",
    "            \n",
    "        Returns:\n",
    "            List[Dict]: Danh sách kết quả cho mỗi file âm thanh\n",
    "        \"\"\"\n",
    "        all_results = []\n",
    "        \n",
    "        # Tạo thư mục chứa file jsonl nếu chưa tồn tại\n",
    "        os.makedirs(os.path.dirname(os.path.abspath(self.json_output_dir)), exist_ok=True)\n",
    "        \n",
    "        # Kiểm tra xem file jsonl có tồn tại chưa\n",
    "        if not os.path.exists(self.json_output_dir):\n",
    "            with open(self.json_output_dir, 'w', encoding='utf-8') as f:\n",
    "                pass  # Tạo file trống\n",
    "        \n",
    "        # Xử lý theo batch\n",
    "        total_batches = (len(audio_paths) + batch_size - 1) // batch_size\n",
    "        for i in range(0, len(audio_paths), batch_size):\n",
    "            batch_audio_paths = audio_paths[i:i+batch_size]\n",
    "            batch_texts = []\n",
    "            batch_langs = []\n",
    "            \n",
    "            print(f\"Đang xử lý batch {i//batch_size + 1}/{total_batches}\")\n",
    "            \n",
    "            # Bước 1: Chuyển tất cả audio thành text\n",
    "            for audio_path in tqdm(batch_audio_paths, desc=\"Chuyển đổi audio thành text\"):\n",
    "                try:\n",
    "                    # Sử dụng phương thức transcribe() có sẵn\n",
    "                    text, lang = self.transcribe(audio_path)\n",
    "                    batch_texts.append(text)\n",
    "                    batch_langs.append(lang)\n",
    "                except Exception as e:\n",
    "                    print(f\"Lỗi khi chuyển đổi {audio_path}: {str(e)}\")\n",
    "                    # Thêm None để giữ index khớp với audio_paths\n",
    "                    batch_texts.append(None)\n",
    "                    batch_langs.append(None)\n",
    "            \n",
    "            # Bước 2: Lọc bỏ các file bị lỗi\n",
    "            valid_texts = []\n",
    "            valid_langs = []\n",
    "            valid_paths = []\n",
    "            for text, lang, path in zip(batch_texts, batch_langs, batch_audio_paths):\n",
    "                if text is not None:\n",
    "                    valid_texts.append(text)\n",
    "                    valid_langs.append(lang)\n",
    "                    valid_paths.append(path)\n",
    "            \n",
    "            # Bước 3: Thực hiện dịch theo batch\n",
    "            if valid_texts:\n",
    "                batch_results = self.batch_translation(\n",
    "                    valid_texts, valid_langs, valid_paths\n",
    "                )\n",
    "                \n",
    "                # Bước 4: Lưu kết quả\n",
    "                for result in tqdm(batch_results, desc=\"Lưu kết quả\"):\n",
    "                    self.save_to_jsonl(result)\n",
    "                    all_results.append(result)\n",
    "        \n",
    "        print(f\"Đã hoàn thành xử lý {len(all_results)}/{len(audio_paths)} file\")\n",
    "        print(f\"Kết quả đã được lưu vào {self.json_output_dir}\")\n",
    "        return all_results\n",
    "    def run_parallel(self, audio_paths, num_workers=None, use_gpu_per_process=False):\n",
    "        \"\"\"\n",
    "        Process multiple audio files in parallel using multiprocessing\n",
    "        \n",
    "        Args:\n",
    "            audio_paths: List of audio file paths to process\n",
    "            num_workers: Number of worker processes (default: number of CPU cores - 1)\n",
    "            use_gpu_per_process: If True, each process gets a different GPU index (for multi-GPU systems)\n",
    "                            If False, all processes use the same device as specified in the constructor\n",
    "        \n",
    "        Returns:\n",
    "            List of dictionaries containing translation results\n",
    "        \"\"\"\n",
    "        if num_workers is None:\n",
    "            num_workers = max(1, cpu_count() - 5)\n",
    "        \n",
    "        # Ensure the output directory exists\n",
    "        os.makedirs(os.path.dirname(os.path.abspath(self.json_output_dir)), exist_ok=True)\n",
    "        \n",
    "        # Create a base config to be passed to each process\n",
    "        base_config = {\n",
    "            'stt_model_name': self.stt_model_name,\n",
    "            'translate_model_name': self.translate_model_name,\n",
    "            'max_text_gen': self.max_text_gen,\n",
    "            'idx': self.idx,\n",
    "            'device': self.device,\n",
    "            'cpu_threads': self.cpu_threads,\n",
    "            'compute_type': self.compute_type,\n",
    "            'src_lang': self.src_lang,\n",
    "            'target_lang': self.target_lang,\n",
    "            'json_output_dir': self.json_output_dir\n",
    "        }\n",
    "        \n",
    "        # Prepare args for each file\n",
    "        args_list = []\n",
    "        for i, audio_path in enumerate(audio_paths):\n",
    "            # Create a copy of the base config\n",
    "            config = base_config.copy()\n",
    "            \n",
    "            # If using multiple GPUs, assign different GPU indices\n",
    "            if use_gpu_per_process:\n",
    "                config['idx'] = i % torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
    "            \n",
    "            # Create a temporary output file for each process to avoid write conflicts\n",
    "            config['temp_output_dir'] = f\"temp_{i}_{os.path.basename(self.json_output_dir)}\"\n",
    "            \n",
    "            args_list.append((audio_path, config))\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Process files in parallel\n",
    "        with Pool(processes=num_workers) as pool:\n",
    "            for result in tqdm(pool.imap_unordered(process_file_with_run, args_list),\n",
    "                            total=len(audio_paths),\n",
    "                            desc=\"Processing audio files\"):\n",
    "                if result['success']:\n",
    "                    results.append(result['result'])\n",
    "                else:\n",
    "                    print(f\"Error processing {result['audio_path']}: {result['error']}\")\n",
    "        \n",
    "        # Merge all temporary output files into the final output file\n",
    "        with open(self.json_output_dir, 'w', encoding='utf-8') as final_file:\n",
    "            for i, _ in enumerate(args_list):\n",
    "                temp_file_path = f\"temp_{i}_{os.path.basename(self.json_output_dir)}\"\n",
    "                if os.path.exists(temp_file_path):\n",
    "                    with open(temp_file_path, 'r', encoding='utf-8') as temp_file:\n",
    "                        final_file.write(temp_file.read())\n",
    "                        if i < len(args_list) - 1:\n",
    "                            final_file.write('\\n')\n",
    "                    # Remove temporary file\n",
    "                    os.remove(temp_file_path)\n",
    "        \n",
    "        print(f\"Completed processing {len(results)}/{len(audio_paths)} files\")\n",
    "        print(f\"Results saved to {self.json_output_dir}\")\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "d:\\projects\\v2v\\v5\\.conda\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\PC\\.cache\\huggingface\\hub\\models--Emilio407--nllb-200-3.3B-8bit. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "processor = Audio2Text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 652/5672 [30:24<1:22:31,  1.01it/s] `low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 12%|█▏        | 663/5672 [30:40<1:22:33,  1.01it/s]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 12%|█▏        | 679/5672 [31:01<1:20:22,  1.04it/s]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 16%|█▌        | 917/5672 [40:45<3:07:09,  2.36s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 16%|█▌        | 920/5672 [40:55<3:39:19,  2.77s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 17%|█▋        | 982/5672 [44:25<7:52:52,  6.05s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 18%|█▊        | 993/5672 [45:15<5:02:29,  3.88s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 18%|█▊        | 1000/5672 [45:57<7:35:18,  5.85s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 18%|█▊        | 1020/5672 [47:29<5:02:47,  3.91s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 18%|█▊        | 1026/5672 [48:00<6:19:02,  4.90s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 18%|█▊        | 1040/5672 [49:08<5:29:08,  4.26s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 26%|██▋       | 1497/5672 [1:15:11<2:58:55,  2.57s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 26%|██▋       | 1498/5672 [1:15:23<6:14:49,  5.39s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 31%|███       | 1770/5672 [1:34:30<3:12:52,  2.97s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 31%|███▏      | 1773/5672 [1:34:47<4:43:01,  4.36s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 31%|███▏      | 1774/5672 [1:34:56<6:18:32,  5.83s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 31%|███▏      | 1775/5672 [1:35:03<6:45:44,  6.25s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 31%|███▏      | 1777/5672 [1:35:20<7:45:34,  7.17s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 31%|███▏      | 1778/5672 [1:35:29<8:33:31,  7.91s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 31%|███▏      | 1780/5672 [1:35:44<8:08:21,  7.53s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 31%|███▏      | 1781/5672 [1:35:54<8:59:01,  8.31s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 31%|███▏      | 1783/5672 [1:36:09<8:13:56,  7.62s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 31%|███▏      | 1784/5672 [1:36:17<8:34:25,  7.94s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 31%|███▏      | 1785/5672 [1:36:26<8:53:41,  8.24s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 32%|███▏      | 1788/5672 [1:36:47<7:44:53,  7.18s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 32%|███▏      | 1789/5672 [1:36:56<8:10:50,  7.58s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 32%|███▏      | 1790/5672 [1:37:05<8:41:25,  8.06s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 32%|███▏      | 1795/5672 [1:37:34<6:10:47,  5.74s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 32%|███▏      | 1797/5672 [1:37:50<7:18:16,  6.79s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 32%|███▏      | 1800/5672 [1:38:05<5:41:27,  5.29s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 32%|███▏      | 1804/5672 [1:38:33<6:51:06,  6.38s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 32%|███▏      | 1813/5672 [1:39:27<7:03:44,  6.59s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 32%|███▏      | 1816/5672 [1:39:43<5:48:03,  5.42s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 32%|███▏      | 1820/5672 [1:40:04<5:08:51,  4.81s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 35%|███▍      | 1983/5672 [1:49:01<5:44:09,  5.60s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 35%|███▌      | 1998/5672 [1:50:07<4:00:42,  3.93s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 36%|███▌      | 2028/5672 [1:52:38<5:49:57,  5.76s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 55%|█████▌    | 3141/5672 [2:54:27<3:18:52,  4.71s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 57%|█████▋    | 3206/5672 [2:59:47<3:03:59,  4.48s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 57%|█████▋    | 3210/5672 [3:00:06<2:54:21,  4.25s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 57%|█████▋    | 3211/5672 [3:00:15<3:46:50,  5.53s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 86%|████████▌ | 4878/5672 [4:43:30<1:13:50,  5.58s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 86%|████████▌ | 4883/5672 [4:43:58<1:04:14,  4.89s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 86%|████████▌ | 4884/5672 [4:44:05<1:15:36,  5.76s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 87%|████████▋ | 4939/5672 [4:48:13<49:35,  4.06s/it]  `low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 90%|█████████ | 5111/5672 [5:01:21<48:00,  5.13s/it]  `low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 90%|█████████ | 5128/5672 [5:02:38<33:06,  3.65s/it]  `low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 90%|█████████ | 5133/5672 [5:03:03<38:51,  4.33s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 91%|█████████ | 5147/5672 [5:04:16<41:05,  4.70s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      " 91%|█████████ | 5155/5672 [5:04:57<43:30,  5.05s/it]`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "100%|██████████| 5672/5672 [5:35:40<00:00,  3.55s/it]\n"
     ]
    }
   ],
   "source": [
    "for audio in tqdm(audio_list):\n",
    "    try:\n",
    "        result = processor.run(audio)\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi xử lý {audio}: {e}\")\n",
    "        continue  # Bỏ qua video lỗi và tiếp tục với video tiếp theo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
