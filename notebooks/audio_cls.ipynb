{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\v2v\\v5\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số mẫu trong CSV: 8278\n",
      "0    [1, 7, 8, 10, 11]\n",
      "1               [8, 9]\n",
      "2                 [10]\n",
      "3             [10, 11]\n",
      "4               [8, 9]\n",
      "Name: label, dtype: object\n",
      "labels shape: (8278, 18)\n",
      "label classes: ['0' '1' '10' '11' '12' '13' '14' '15' '16' '17' '2' '3' '4' '5' '6' '7'\n",
      " '8' '9']\n",
      "train_labels shape: (6622, 18)\n",
      "val_labels shape: (1656, 18)\n",
      "len(train_audio_paths): 6622\n",
      "len(val_audio_paths): 1656\n",
      "train_labels dtype: int64\n",
      "Sample train_labels[0]: [0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_labels dtype after conversion: float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\v2v\\v5\\.conda\\lib\\site-packages\\transformers\\configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2Processor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import MultilabelAccuracy, MultilabelPrecision, MultilabelAveragePrecision\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Đọc và chuẩn hóa dữ liệu ---\n",
    "data = pd.read_csv(\"audio_only_classification_dataset.csv\")\n",
    "print(f\"Số mẫu trong CSV: {len(data)}\")\n",
    "data['label'] = data['label'].apply(lambda x: [label.strip() for label in x.split(',')])  # Chuẩn hóa nhãn\n",
    "print(data['label'].head())\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(data['label'])\n",
    "label_classes = mlb.classes_\n",
    "print(f\"labels shape: {labels.shape}\")\n",
    "print(f\"label classes: {label_classes}\")\n",
    "\n",
    "audio_paths = data['audio_id'].values\n",
    "train_audio_paths, val_audio_paths, train_labels, val_labels = train_test_split(\n",
    "    audio_paths, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"train_labels shape: {train_labels.shape}\")\n",
    "print(f\"val_labels shape: {val_labels.shape}\")\n",
    "print(f\"len(train_audio_paths): {len(train_audio_paths)}\")\n",
    "print(f\"len(val_audio_paths): {len(val_audio_paths)}\")\n",
    "print(f\"train_labels dtype: {train_labels.dtype}\")\n",
    "print(f\"Sample train_labels[0]: {train_labels[0]}\")\n",
    "\n",
    "# Chuyển đổi nhãn sang float32\n",
    "train_labels = train_labels.astype(np.float32)\n",
    "val_labels = val_labels.astype(np.float32)\n",
    "print(f\"train_labels dtype after conversion: {train_labels.dtype}\")\n",
    "\n",
    "# --- Tiền xử lý âm thanh ---\n",
    "def preprocess_audio(audio_path, sample_rate=16000, max_length=5.0):\n",
    "    waveform, sr = torchaudio.load(audio_path)\n",
    "    if sr != sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(sr, sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "    max_samples = int(max_length * sample_rate)\n",
    "    if waveform.shape[1] > max_samples:\n",
    "        waveform = waveform[:, :max_samples]\n",
    "    else:\n",
    "        padding = max_samples - waveform.shape[1]\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
    "    assert waveform.shape == (1, max_samples), f\"Waveform shape không đúng: {waveform.shape}\"\n",
    "    return waveform\n",
    "\n",
    "# --- Transform cho Wav2Vec2 ---\n",
    "processor = Wav2Vec2Processor.from_pretrained('facebook/wav2vec2-base')\n",
    "def transform_waveform(waveform):\n",
    "    if waveform.ndim == 2:\n",
    "        waveform = waveform.squeeze(0)\n",
    "    assert waveform.ndim == 1, f\"Waveform phải là 1D, nhận được shape: {waveform.shape}\"\n",
    "    inputs = processor(waveform, sampling_rate=16000, return_tensors='pt', padding=True)\n",
    "    print(inputs['input_values'].shape)\n",
    "    input_values = inputs['input_values'].squeeze()\n",
    "    if input_values.ndim == 2:\n",
    "        input_values = input_values[0]\n",
    "    assert input_values.ndim == 1, f\"input_values phải là 1D, nhận được shape: {input_values.shape}\"\n",
    "    print(input_values.shape)\n",
    "    print(\"-------\")\n",
    "    return input_values\n",
    "\n",
    "# --- Định nghĩa Dataset ---\n",
    "class AudioMultilabelDataset(Dataset):\n",
    "    def __init__(self, audio_paths, labels, transform=None, sample_rate=16000, max_length=5.0):\n",
    "        self.audio_paths = audio_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.sample_rate = sample_rate\n",
    "        self.max_length = max_length\n",
    "        # print(f\"Dataset labels shape: {labels.shape}\")\n",
    "        assert len(audio_paths) == labels.shape[0], f\"Số mẫu không khớp: {len(audio_paths)} vs {labels.shape[0]}\"\n",
    "        assert labels.shape[1] == len(label_classes), f\"Số nhãn không khớp: {labels.shape[1]} vs {len(label_classes)}\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.audio_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        waveform = preprocess_audio(audio_path, self.sample_rate, self.max_length)\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "        \n",
    "        # print(f\"idx: {idx}, waveform shape: {waveform.shape}, label shape: {label.shape}\")\n",
    "        assert waveform.ndim == 1, f\"Waveform shape không đúng: {waveform.shape}\"\n",
    "        assert label.shape == (len(label_classes),), f\"Label shape không đúng: {label.shape}\"\n",
    "        \n",
    "        labels_tensor = torch.FloatTensor(label).to(dtype=torch.float32)\n",
    "        # print(f\"Label dtype: {labels_tensor.dtype}\")\n",
    "        return {\n",
    "            'input_values': waveform,\n",
    "            'labels': labels_tensor\n",
    "        }\n",
    "\n",
    "# --- Tạo dataset ---\n",
    "train_dataset = AudioMultilabelDataset(train_audio_paths, train_labels, transform=transform_waveform, max_length = 60)\n",
    "val_dataset = AudioMultilabelDataset(val_audio_paths, val_labels, transform=transform_waveform,max_length = 60)\n",
    "\n",
    "# --- Collate function ---\n",
    "def collate_fn(batch):\n",
    "    input_values = torch.stack([item['input_values'] for item in batch])\n",
    "    labels = torch.stack([item['labels'] for item in batch])\n",
    "    # print(f\"Batch input_values shape: {input_values.shape}\")\n",
    "    # print(f\"Batch labels shape: {labels.shape}\")\n",
    "    assert input_values.shape[0] == len(batch), f\"Batch size input_values không đúng: {input_values.shape[0]}\"\n",
    "    assert labels.shape == (len(batch), len(label_classes)), f\"Batch labels shape không đúng: {labels.shape}\"\n",
    "    return {\n",
    "        'input_values': input_values,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "# --- Tạo DataLoader ---\n",
    "batch_size = 8  # Có thể thử batch_size=1 để debug\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# --- Định nghĩa mô hình phân loại đa nhãn ---\n",
    "class MultilabelWav2Vec2(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(MultilabelWav2Vec2, self).__init__()\n",
    "        self.wav2vec2 = Wav2Vec2Model.from_pretrained('facebook/wav2vec2-base')\n",
    "        self.classifier = nn.Linear(self.wav2vec2.config.hidden_size, num_labels)\n",
    "        \n",
    "    def forward(self, input_values):\n",
    "        outputs = self.wav2vec2(input_values)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # Lấy [CLS] token hoặc mean pooling\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# --- Khởi tạo mô hình, hàm mất mát, optimizer ---\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import time\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MultilabelWav2Vec2(num_labels=len(label_classes)).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()  # Phù hợp cho phân loại đa nhãn\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.005)\n",
    "\n",
    "# Thiết lập optimizer với learning rate thích hợp và weight decay\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)\n",
    "\n",
    "# Thêm learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1, verbose=True)\n",
    "\n",
    "# Gradient accumulation cho batch size lớn hơn trên GPU nhỏ\n",
    "accumulation_steps = 2\n",
    "\n",
    "# Mixed precision training\n",
    "scaler = torch.amp.GradScaler(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hàm tính metrics ---\n",
    "# def compute_metrics(logits, labels, device):\n",
    "#     binary_preds = (logits > 0).int()  # Chuyển logits thành nhãn nhị phân (0 hoặc 1)\n",
    "    \n",
    "#     logits_tensor = logits.to(device)\n",
    "#     binary_preds_tensor = binary_preds.to(device)\n",
    "#     labels_tensor = labels.to(dtype=torch.int32).to(device)  # Chuyển nhãn sang int32\n",
    "    \n",
    "#     acc = MultilabelAccuracy(num_labels=labels.shape[1], average='macro').to(device)\n",
    "#     precision_metric = MultilabelAccuracy(num_labels=labels.shape[1], average='micro').to(device)\n",
    "#     mAP = MultilabelAveragePrecision(num_labels=labels.shape[1]).to(device)\n",
    "    \n",
    "#     acc_value = acc(binary_preds_tensor, labels_tensor).item()\n",
    "#     precision_value = precision_metric(binary_preds_tensor, labels_tensor).item()\n",
    "#     map_value = mAP(logits_tensor, labels_tensor).item()  # mAP vẫn dùng logits_tensor\n",
    "    \n",
    "#     return {\n",
    "#         'accuracy': acc_value,\n",
    "#         'precision': precision_value,\n",
    "#         'mAP': map_value\n",
    "#     }\n",
    "\n",
    "def compute_metrics(logits, labels, device):\n",
    "    # Sử dụng torch.sigmoid để có giá trị dự đoán tốt hơn\n",
    "    probs = torch.sigmoid(logits)\n",
    "    binary_preds = (probs > 0.5).int()\n",
    "    \n",
    "    # Chuyển nhãn sang int32 cho torchmetrics\n",
    "    labels = labels.to(dtype=torch.int32)\n",
    "    \n",
    "    # Tính toán metrics một lần trên batch\n",
    "    acc = MultilabelAccuracy(num_labels=labels.shape[1], average='macro').to(device)\n",
    "    precision_metric = MultilabelPrecision(num_labels=labels.shape[1], average='micro').to(device)\n",
    "    mAP = MultilabelAveragePrecision(num_labels=labels.shape[1]).to(device)\n",
    "    \n",
    "    acc_value = acc(binary_preds, labels).item()\n",
    "    precision_value = precision_metric(binary_preds, labels).item()\n",
    "    map_value = mAP(probs, labels).item()  # Sử dụng probs thay vì logits\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc_value,\n",
    "        'precision': precision_value,\n",
    "        'mAP': map_value\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/828 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 960000])\n",
      "torch.Size([960000])\n",
      "-------\n",
      "torch.Size([1, 960000])\n",
      "torch.Size([960000])\n",
      "-------\n",
      "torch.Size([1, 960000])\n",
      "torch.Size([960000])\n",
      "-------\n",
      "torch.Size([1, 960000])\n",
      "torch.Size([960000])\n",
      "-------\n",
      "torch.Size([1, 960000])\n",
      "torch.Size([960000])\n",
      "-------\n",
      "torch.Size([1, 960000])\n",
      "torch.Size([960000])\n",
      "-------\n",
      "torch.Size([1, 960000])\n",
      "torch.Size([960000])\n",
      "-------\n",
      "torch.Size([1, 960000])\n",
      "torch.Size([960000])\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/828 [00:16<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(logits, labels) \u001b[38;5;241m/\u001b[39m accumulation_steps\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Gradient accumulation\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Gradient clipping để tránh exploding gradients\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     scaler\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n",
      "File \u001b[1;32md:\\projects\\v2v\\v5\\.conda\\lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\projects\\v2v\\v5\\.conda\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\projects\\v2v\\v5\\.conda\\lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Early stopping\n",
    "best_val_map = 0\n",
    "patience = 1\n",
    "patience_counter = 0\n",
    "early_stop = False\n",
    "\n",
    "num_epochs = 2  # Tăng số epochs\n",
    "for epoch in range(num_epochs):\n",
    "    if early_stop:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break\n",
    "        \n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_metrics = {'accuracy': 0.0, 'precision': 0.0, 'mAP': 0.0}\n",
    "    num_batches = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        input_values = batch['input_values'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Sử dụng mixed precision\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            logits = model(input_values)\n",
    "            loss = criterion(logits, labels) / accumulation_steps\n",
    "        \n",
    "        # Gradient accumulation\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_loader):\n",
    "            # Gradient clipping để tránh exploding gradients\n",
    "            scaler.unscale_(optimizer)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        train_loss += loss.item() * accumulation_steps\n",
    "        \n",
    "        # Tính metrics chỉ với một tỷ lệ nhất định các batch để tăng tốc\n",
    "        if i % 5 == 0:  # Tính metrics mỗi 5 batch\n",
    "            metrics = compute_metrics(logits, labels, device)\n",
    "            for key in train_metrics:\n",
    "                train_metrics[key] += metrics[key]\n",
    "            num_batches += 1\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    for key in train_metrics:\n",
    "        train_metrics[key] /= max(num_batches, 1)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_metrics = {'accuracy': 0.0, 'precision': 0.0, 'mAP': 0.0}\n",
    "    num_batches = 0\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            input_values = batch['input_values'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            with torch.amp.autocast('cuda'):\n",
    "                logits = model(input_values)\n",
    "                loss = criterion(logits, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Thu thập tất cả logits và labels để tính metrics một lần duy nhất\n",
    "            all_logits.append(logits.detach())\n",
    "            all_labels.append(labels.detach())\n",
    "            num_batches += 1\n",
    "    \n",
    "    # Tính metrics một lần trên toàn bộ validation set\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    val_metrics = compute_metrics(all_logits, all_labels, device)\n",
    "    \n",
    "    val_loss /= num_batches\n",
    "    \n",
    "    # Cập nhật learning rate dựa trên validation loss\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Early stopping check\n",
    "    if val_metrics['mAP'] > best_val_map:\n",
    "        best_val_map = val_metrics['mAP']\n",
    "        patience_counter = 0\n",
    "        # Lưu model tốt nhất\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "        print(\"Saved best model!\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            early_stop = True\n",
    "    \n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Time: {epoch_time:.2f}s, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_metrics['accuracy']:.4f}, \"\n",
    "          f\"Train Precision: {train_metrics['precision']:.4f}, Train mAP: {train_metrics['mAP']:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_metrics['accuracy']:.4f}, \"\n",
    "          f\"Val Precision: {val_metrics['precision']:.4f}, Val mAP: {val_metrics['mAP']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/828 [00:00<?, ?it/s]d:\\projects\\v2v\\v5\\.conda\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: No positive samples found in target, recall is undefined. Setting recall to one for all thresholds.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 1/5:   2%|▏         | 15/828 [10:26<9:53:06, 43.77s/it]"
     ]
    }
   ],
   "source": [
    "# --- Vòng huấn luyện ---\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_metrics = {'accuracy': 0.0, 'precision': 0.0, 'mAP': 0.0}\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        input_values = batch['input_values'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_values)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        metrics = compute_metrics(logits, labels, device)\n",
    "        for key in train_metrics:\n",
    "            train_metrics[key] += metrics[key]\n",
    "        num_batches += 1\n",
    "    \n",
    "    train_loss /= num_batches\n",
    "    for key in train_metrics:\n",
    "        train_metrics[key] /= num_batches\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, \"\n",
    "          f\"Train Accuracy: {train_metrics['accuracy']:.4f}, \"\n",
    "          f\"Train Precision: {train_metrics['precision']:.4f}, \"\n",
    "          f\"Train mAP: {train_metrics['mAP']:.4f}\")\n",
    "    \n",
    "    # Đánh giá trên tập validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_metrics = {'accuracy': 0.0, 'precision': 0.0, 'mAP': 0.0}\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            input_values = batch['input_values'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            logits = model(input_values)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            metrics = compute_metrics(logits, labels, device)\n",
    "            for key in val_metrics:\n",
    "                val_metrics[key] += metrics[key]\n",
    "            num_batches += 1\n",
    "    \n",
    "    val_loss /= num_batches\n",
    "    for key in val_metrics:\n",
    "        val_metrics[key] /= num_batches\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Val Loss: {val_loss:.4f}, \"\n",
    "          f\"Val Accuracy: {val_metrics['accuracy']:.4f}, \"\n",
    "          f\"Val Precision: {val_metrics['precision']:.4f}, \"\n",
    "          f\"Val mAP: {val_metrics['mAP']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
