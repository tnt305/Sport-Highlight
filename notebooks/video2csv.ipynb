{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas\n",
    "from tqdm import tqdm \n",
    "from collections import defaultdict\n",
    "from src.models.video.labels import EVENT_DICTIONARY_V2\n",
    "from src.preprocessing.video import(\n",
    "    json_reader,\n",
    "    round_down_to_minute,\n",
    "    round_down_to_minute_v2,\n",
    "    normalize_path,\n",
    "    round_down_to_minute_half\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_DICT = {key: index for index, key in enumerate(EVENT_DICTIONARY_V2.keys())}\n",
    "EVENT_DICT\n",
    "video_path = os.listdir(\"F:/video_classification\")\n",
    "video_paths = [f\"F:/video_classification/{i}\" for i in video_path]\n",
    "\n",
    "labels = [normalize_path(glob.glob(f\"F:/video_classification/{i}/*.json\")[0]) for i in video_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:01<00:00, 58.80it/s]\n"
     ]
    }
   ],
   "source": [
    "NO_NEEDED_CLASSES = []\n",
    "for games in tqdm(video_paths):\n",
    "    # print(games)\n",
    "    anno_path = normalize_path(os.path.join(games, 'Labels-v2.json'))\n",
    "    annos = json_reader(anno_path)['annotations']\n",
    "    # Bỏ qua các frames mà không được show\n",
    "    # tức là các frame này khả năng cao không có ý nghĩa\n",
    "    \n",
    "    # annos_v2 = [\n",
    "    #     item for item in annos \n",
    "    #     if item['visibility'] != 'not shown' \n",
    "            # and item['label'] not in NO_NEEDED_CLASSES\n",
    "        # ]\n",
    "    \n",
    "    # annos_v3 = [item for item in annos_v2\n",
    "    #     if item['label'] == 'Kick-off' and (item['gameTime'].startswith('1 - 00:') \n",
    "    #                                     or item['gameTime'].startswith('2 - 00:'))      \n",
    "        # ]\n",
    "    # print(annos_v3)\n",
    "    \n",
    "    grouped_items = defaultdict(list)\n",
    "    annos_v2 = sorted([\n",
    "        dict(t) for t in {tuple(d.items()) for d in annos}], \n",
    "        key = lambda x: x['gameTime']\n",
    "        )\n",
    "    \n",
    "    for item in annos_v2:\n",
    "        if item['gameTime'].startswith(\"1\"):\n",
    "            group = round_down_to_minute(item['gameTime'].split(' - ')[-1])\n",
    "            # group2 = round_down_to_minute_half(item['gameTime'].split(' - ')[-1], delta = 0)\n",
    "        else:\n",
    "            group = round_down_to_minute_v2(item['gameTime'].split(' - ')[-1])\n",
    "            # group2 = round_down_to_minute_half(item['gameTime'].split(' - ')[-1], delta = 45)\n",
    "        grouped_items[group].append(item['label'])\n",
    "        # grouped_items[group2].append(item['label'])\n",
    "    grouped_items = defaultdict(list, {k: v for k, v in grouped_items.items() if not k.startswith(\"-\")})\n",
    "    # sorted keys chỉ chứa các thông tin về các phút chứa sự kiện\n",
    "    # tức là có thể có CÁC PHÚT không có sự kiện nào xảy ra\n",
    "    # sort_keys là các time-minute \n",
    "    sorted_keys = sorted(\n",
    "            grouped_items.keys(), \n",
    "            key = lambda x: int(x.split(\":\")[0])\n",
    "        )\n",
    "    result = {}\n",
    "    previous_minute = None\n",
    "    \n",
    "    for key in sorted_keys:\n",
    "        current_minute = int(key.split(\":\")[0])\n",
    "        if previous_minute is not None and current_minute > previous_minute +1:\n",
    "            for missing_minute in range(previous_minute + 1, current_minute):\n",
    "                # Xử lý trường hợp có phút bị khuyết thì bổ sung thêm\n",
    "                # Và đặt nó thành list rỗng\n",
    "                result[f\"{missing_minute:02}:00\"] = [\"Event not recognized\"]      \n",
    "        result[key] = grouped_items[key]\n",
    "        previous_minute = current_minute\n",
    "    # # multilabel\n",
    "    result = {k: list(set(v)) for k, v in result.items()}\n",
    "    # print(result)\n",
    "    # print(\"----\")\n",
    "    # create initial dataset\n",
    "    df = pandas.DataFrame({\n",
    "        'chunk': [int(i.split(\":\")[0]) for i in result.keys()],\n",
    "        'video_base_dir': games,\n",
    "        \"timestamp\": result.keys(),\n",
    "        \"labels\": [values for values in result.values()],  # Join list items into a single string\n",
    "    })\n",
    "    \n",
    "    df['labels_encoder'] = df['labels'].apply(\n",
    "        lambda label_list: \", \".join(\n",
    "            str(v) for k, v in EVENT_DICT.items() if k in label_list\n",
    "        ) if label_list else str(list(EVENT_DICT.values())[-1])\n",
    "    )\n",
    "    def get_video_path(row):\n",
    "        minute = int(row['timestamp'].split(':')[0])\n",
    "        return glob.glob(f\"{row['video_base_dir']}/chunk_{minute}/*.mp4\")\n",
    "\n",
    "    df['video_path'] = df.apply(get_video_path, axis=1)\n",
    "    \n",
    "    def get_audio_path(row):\n",
    "        minute = int(row['timestamp'].split(':')[0])\n",
    "        return glob.glob(f\"{row['video_base_dir']}/chunk_{minute}/*.mp3\")\n",
    "\n",
    "    df['audio_path'] = df.apply(get_audio_path, axis=1)\n",
    "    \n",
    "    # df['video_path'] = [normalize_path(i[0]) for i in df['video_path']]\n",
    "    # df['audio_path'] = [normalize_path(i[0]) for i in df['audio_path']]\n",
    "\n",
    "    \n",
    "    \n",
    "    # df = df[['chunk','video_base_dir', 'video_path', 'audio_path', 'timestamp', 'labels', 'labels_encoder']]\n",
    "    \n",
    "    # vdo_paths = []\n",
    "    # ado_paths = []\n",
    "    # for video in df['video_path']:\n",
    "    #     vdo_path = f\"{video}/visual\"\n",
    "    #     ado_path = f\"{video}/audio\"\n",
    "    #     vdo_paths.append(vdo_path)\n",
    "    #     ado_paths.append(ado_path)\n",
    "\n",
    "    # df['new_video_path'] = vdo_paths\n",
    "    # df['new_audio_path'] = ado_paths\n",
    "    df.to_csv(f\"{games}/{games.split('/')[-1]}.csv\", index=False)  \n",
    "    \n",
    "\n",
    "# basedir = \"F:/video_classification\"\n",
    "# csv_files = [f\"{basedir}/{i}/{i}.csv\" for i in os.listdir(basedir)]\n",
    "\n",
    "# import pandas as pd\n",
    "# import glob\n",
    "\n",
    "# # Read and concatenate all CSVs\n",
    "# df2 = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
    "# # df2 = df2[~df2['video_path'].apply(lambda x: x == [])]\n",
    "\n",
    "# video_ids = []\n",
    "# for i in df2['video_path']:\n",
    "#     ites = i.replace('[', '').replace(']', '')\n",
    "#     ites = ites.replace(\"'\", '').replace(\"'\", '')\n",
    "#     video_ids.append(normalize_path(ites))\n",
    "# df2['video_id'] = video_ids\n",
    "\n",
    "# audio_ids = []\n",
    "# for i in df2['audio_path']:\n",
    "#     ites = i.replace('[', '').replace(']', '')\n",
    "#     ites = ites.replace(\"'\", '').replace(\"'\", '')\n",
    "#     audio_ids.append(normalize_path(ites))\n",
    "# df2['audio_id'] = audio_ids\n",
    "\n",
    "# df2 = df2[['chunk', 'video_base_dir', 'video_id', 'audio_id', 'labels_encoder']].rename(columns={'labels_encoder': 'labels'})\n",
    "# # Save the merged CSV\n",
    "# df2.to_csv(\"dataset.csv\", index=False, sep = \";\")\n",
    "\n",
    "# print(\"CSV files concatenated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 12/91 [00:00<00:00, 117.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 91 2014-11-04 - 20-00 Zenit Petersburg 1 - 2 Bayer Leverkusen\n",
      "89 89 2015-02-14 - 20-00 Real Madrid 2 - 0 Dep. La Coruna\n",
      "92 93 2015-02-24 - 22-45 Manchester City 1 - 2 Barcelona\n",
      "92 93 2015-03-10 - 22-45 Real Madrid 3 - 4 Schalke\n",
      "89 89 2015-03-17 - 22-45 Monaco 0 - 2 Arsenal\n",
      "86 87 2015-04-15 - 21-45 FC Porto 3 - 1 Bayern Munich\n",
      "91 92 2015-04-18 - 21-00 Real Madrid 3 - 1 Malaga\n",
      "93 94 2015-04-22 - 21-45 Real Madrid 1 - 0 Atl. Madrid\n",
      "91 91 2015-04-25 - 17-00 Espanyol 0 - 2 Barcelona\n",
      "89 90 2015-04-29 - 21-00 Real Madrid 3 - 0 Almeria\n",
      "89 90 2015-04-29 - 21-45 Juventus 3 - 2 Fiorentina\n",
      "87 88 2015-05-02 - 17-00 Cordoba 0 - 8 Barcelona\n",
      "92 92 2015-05-05 - 21-45 Juventus 2 - 1 Real Madrid\n",
      "91 92 2015-05-09 - 16-30 Bayern Munich 0 - 1 FC Augsburg\n",
      "91 92 2015-05-09 - 19-00 Barcelona 2 - 0 Real Sociedad\n",
      "90 91 2015-08-16 - 18-00 Manchester City 3 - 0 Chelsea\n",
      "89 89 2015-08-23 - 15-30 West Brom 2 - 3 Chelsea\n",
      "95 96 2015-08-29 - 17-00 Liverpool 0 - 3 West Ham\n",
      "89 89 2015-08-29 - 19-30 Bayern Munich 3 - 0 Bayer Leverkusen\n",
      "89 89 2015-08-29 - 21-45 AC Milan 2 - 1 Empoli\n",
      "91 91 2015-08-29 - 23-30 Real Madrid 5 - 0 Betis\n",
      "92 92 2015-09-12 - 16-30 Bayern Munich 2 - 1 FC Augsburg\n",
      "89 89 2015-09-19 - 17-00 Real Madrid 1 - 0 Granada CF\n",
      "89 89 2015-09-20 - 16-00 Genoa 0 - 2 Juventus\n",
      "89 89 2015-09-20 - 18-00 Southampton 2 - 3 Manchester United\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 39/91 [00:00<00:00, 125.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 97 2015-09-26 - 19-30 Newcastle Utd 2 - 2 Chelsea\n",
      "90 90 2015-09-27 - 21-45 Inter 1 - 4 Fiorentina\n",
      "89 89 2015-09-29 - 21-45 Bayern Munich 5 - 0 D. Zagreb\n",
      "91 91 2015-10-03 - 19-30 Chelsea 1 - 3 Southampton\n",
      "86 87 2015-10-24 - 16-30 Bayern Munich 4 - 0 FC Koln\n",
      "91 92 2015-11-03 - 22-45 Real Madrid 1 - 0 Paris SG\n",
      "90 90 2015-11-03 - 22-45 Sevilla 1 - 3 Manchester City\n",
      "89 90 2015-11-07 - 20-30 Stoke City 1 - 0 Chelsea\n",
      "93 93 2015-11-08 - 17-30 Dortmund 3 - 2 Schalke\n",
      "90 91 2015-11-08 - 19-00 Arsenal 1 - 1 Tottenham\n",
      "89 89 2015-11-25 - 22-45 Shakhtar Donetsk 3 - 4 Real Madrid\n",
      "88 89 2016-02-03 - 22-45 Watford 0 - 0 Chelsea\n",
      "87 88 2016-03-01 - 22-45 Norwich 1 - 2 Chelsea\n",
      "90 90 2016-04-05 - 21-45 Bayern Munich 1 - 0 Benfica\n",
      "89 89 2016-05-08 - 18-00 Real Madrid 3 - 2 Valencia\n",
      "89 89 2016-05-14 - 18-00 Dep. La Coruna 0 - 2 Real Madrid\n",
      "92 93 2016-08-27 - 14-30 Tottenham 1 - 1 Liverpool\n",
      "93 93 2016-08-27 - 21-45 Napoli 4 - 2 AC Milan\n",
      "90 91 2016-08-28 - 21-45 Monaco 3 - 1 Paris SG\n",
      "89 89 2016-09-10 - 19-30 RB Leipzig 1 - 0 Dortmund\n",
      "89 89 2016-09-10 - 21-30 Barcelona 1 - 2 Alaves\n",
      "94 94 2016-09-11 - 16-00 AC Milan 0 - 1 Udinese\n",
      "88 89 2016-09-20 - 21-45 AC Milan 2 - 0 Lazio\n",
      "92 93 2016-09-21 - 21-00 Real Madrid 1 - 1 Villarreal\n",
      "89 89 2016-09-24 - 14-30 Manchester United 4 - 1 Leicester\n",
      "90 90 2016-09-24 - 21-45 Las Palmas 2 - 2 Real Madrid\n",
      "89 89 2016-09-24 - 21-45 Napoli 2 - 0 Chievo\n",
      "89 89 2016-09-25 - 13-30 Torino 3 - 1 AS Roma\n",
      "93 94 2016-09-25 - 21-45 Fiorentina 0 - 0 AC Milan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 68/91 [00:00<00:00, 127.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 90 2016-10-01 - 19-30 Bayer Leverkusen 2 - 0 Dortmund\n",
      "89 90 2016-10-02 - 21-45 AS Roma 2 - 1 Inter\n",
      "89 89 2016-10-15 - 14-30 Chelsea 3 - 0 Leicester\n",
      "87 88 2016-11-01 - 20-45 Besiktas 1 - 1 Napoli\n",
      "89 89 2016-11-01 - 22-45 Manchester City 3 - 1 Barcelona\n",
      "89 89 2016-11-05 - 17-30 Hamburger SV 2 - 5 Dortmund\n",
      "89 90 2016-11-19 - 20-30 Dortmund 1 - 0 Bayern Munich\n",
      "92 93 2016-11-20 - 17-00 Atalanta 2 - 1 AS Roma\n",
      "88 89 2016-11-23 - 22-45 Arsenal 2 - 2 Paris SG\n",
      "87 88 2016-11-26 - 18-15 Real Madrid 2 - 1 Gijon\n",
      "89 89 2016-11-26 - 22-45 Empoli 1 - 4 AC Milan\n",
      "89 89 2016-11-30 - 23-00 Paris SG 2 - 0 Angers\n",
      "94 94 2016-12-04 - 17-00 Lazio 0 - 2 AS Roma\n",
      "92 92 2016-12-16 - 22-30 Hoffenheim 2 - 2 Dortmund\n",
      "89 89 2016-12-18 - 22-45 Barcelona 4 - 1 Espanyol\n",
      "89 89 2017-01-08 - 17-00 Genoa 0 - 1 AS Roma\n",
      "94 94 2017-01-21 - 15-30 Liverpool 2 - 3 Swansea\n",
      "89 89 2017-01-21 - 17-30 SV Werder Bremen 1 - 2 Dortmund\n",
      "90 91 2017-01-29 - 17-00 Sampdoria 3 - 2 AS Roma\n",
      "89 89 2017-01-29 - 19-30 1. FSV Mainz 05 1 - 1 Dortmund\n",
      "89 89 2017-02-07 - 22-45 AS Roma 4 - 0 Fiorentina\n",
      "93 93 2017-02-11 - 22-45 Osasuna 1 - 3 Real Madrid\n",
      "91 91 2017-02-25 - 20-00 Napoli 0 - 2 Atalanta\n",
      "89 89 2017-02-26 - 22-45 Inter 1 - 3 AS Roma\n",
      "90 91 2017-03-04 - 17-30 Dortmund 6 - 2 Bayer Leverkusen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:00<00:00, 128.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 94 2017-03-08 - 22-45 Barcelona 6 - 1 Paris SG\n",
      "89 89 2017-03-12 - 22-45 Real Madrid 2 - 1 Betis\n",
      "89 89 2017-04-01 - 21-45 AS Roma 2 - 0 Empoli\n",
      "89 89 2017-04-02 - 17-15 Real Madrid 3 - 0 Alaves\n",
      "88 89 2017-04-08 - 21-45 Malaga 2 - 0 Barcelona\n",
      "90 91 2017-04-12 - 21-45 Bayern Munich 1 - 2 Real Madrid\n",
      "89 89 2017-04-26 - 20-30 Barcelona 7 - 1 Osasuna\n",
      "89 89 2017-04-29 - 16-30 Dortmund 0 - 0 FC Koln\n",
      "89 89 2017-04-30 - 21-45 Inter 0 - 1 Napoli\n",
      "89 89 2017-05-02 - 21-45 Real Madrid 3 - 0 Atl. Madrid\n",
      "92 93 2017-05-06 - 17-00 Leicester 3 - 0 Watford\n",
      "86 87 2017-05-20 - 21-45 Napoli 4 - 1 Fiorentina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "import csv\n",
    "import shutil\n",
    "from src.preprocessing.video import normalize_path\n",
    "basedir = \"F:/video_classification\"\n",
    "ass = 0\n",
    "for vdo in tqdm(os.listdir(basedir)):\n",
    "    vdo_path = normalize_path(os.path.join(basedir, vdo))\n",
    "\n",
    "    count_chunk = len([i for i in os.listdir(vdo_path) if os.path.isdir(f\"{vdo_path}/{i}\")]) - 1\n",
    "    count_csv = len(pandas.read_csv(f\"{vdo_path}/{vdo}.csv\", sep = \",\")) - 1\n",
    "    print(count_chunk, count_csv, vdo)\n",
    "    if count_chunk <= 20:\n",
    "        # ass += 1\n",
    "        shutil.rmtree(vdo_path)\n",
    "    elif count_chunk > count_csv:\n",
    "        count_remover = (count_chunk) - (count_csv)\n",
    "        for i in range(count_remover+1):\n",
    "            if os.path.exists(f\"{vdo_path}/chunk_{count_csv + i}\"):\n",
    "                shutil.rmtree(f\"{vdo_path}/chunk_{count_csv + i}\")\n",
    "    elif count_chunk < count_csv:\n",
    "        count_remover = count_csv - count_chunk\n",
    "        readcsv = pandas.read_csv(f\"{vdo_path}/{vdo}.csv\", sep = \",\")\n",
    "        readcsv = readcsv[:-count_remover]\n",
    "        readcsv.to_csv(f\"{vdo_path}/{vdo}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basedir = \"F:/video_classification\"\n",
    "csv_files = [f\"{basedir}/{i}/{i}.csv\" for i in os.listdir(basedir)]\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Read and concatenate all CSVs\n",
    "df2 = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
    "# df2 = df2[~df2['video_path'].apply(lambda x: x == [])]\n",
    "\n",
    "video_ids = []\n",
    "for i in df2['video_path']:\n",
    "    ites = str(i).replace('[', '').replace(']', '')\n",
    "    ites = ites.replace(\"'\", '').replace(\"'\", '')\n",
    "    video_ids.append(normalize_path(ites))\n",
    "df2['video_id'] = video_ids\n",
    "\n",
    "audio_ids = []\n",
    "for i in df2['audio_path']:\n",
    "    ites = str(i).replace('[', '').replace(']', '')\n",
    "    ites = ites.replace(\"'\", '').replace(\"'\", '')\n",
    "    audio_ids.append(normalize_path(ites))\n",
    "df2['audio_id'] = audio_ids\n",
    "\n",
    "df2 = df2[['chunk', 'video_base_dir', 'video_id', 'audio_id', 'labels_encoder']].rename(columns={'labels_encoder': 'labels'})\n",
    "# # Save the merged CSV\n",
    "df2.to_csv(\"dataset2.csv\", index=False, sep = \";\")\n",
    "\n",
    "# print(\"CSV files concatenated successfully!\")\n",
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = []\n",
    "for i in df2['video_path']:\n",
    "    ites = str(i).replace('[', '').replace(']', '')\n",
    "    ites = ites.replace(\"'\", '').replace(\"'\", '')\n",
    "    video_ids.append(normalize_path(ites))\n",
    "df2['video_id'] = video_ids\n",
    "\n",
    "audio_ids = []\n",
    "for i in df2['audio_path']:\n",
    "    ites = str(i).replace('[', '').replace(']', '')\n",
    "    ites = ites.replace(\"'\", '').replace(\"'\", '')\n",
    "    audio_ids.append(normalize_path(ites))\n",
    "df2['audio_id'] = audio_ids\n",
    "\n",
    "df2 = df2[['chunk', 'video_base_dir', 'video_id', 'audio_id', 'labels_encoder']].rename(columns={'labels_encoder': 'labels'})\n",
    "# Save the merged CSV\n",
    "df2.to_csv(\"dataset2.csv\", index=False, sep = \";\")\n",
    "\n",
    "print(\"CSV files concatenated successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
