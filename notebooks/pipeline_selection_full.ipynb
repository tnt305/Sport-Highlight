{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-26 06:43:35 UTC+7\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msrc.logger.log_handler\u001b[0m:\u001b[36mwarning\u001b[0m:\u001b[36m109\u001b[0m | \u001b[33m\u001b[1mThis path is not exist, use default constants\u001b[0m\n",
      "d:\\projects\\v2v\\v5\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of TimesformerModel were not initialized from the model checkpoint at facebook/timesformer-base-finetuned-k600 and are newly initialized because the shapes did not match:\n",
      "- timesformer.embeddings.time_embeddings: found shape torch.Size([1, 8, 768]) in the checkpoint and torch.Size([1, 30, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/99 [00:00<?, ?it/s]`use_fast` is set to `True` but the image processor class does not have a fast version.  Falling back to the slow version.\n",
      "100%|██████████| 99/99 [02:31<00:00,  1.53s/it]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from src.models.video import TimeSformerInferencing\n",
    "from src.post_processing import process_football_events, cfg\n",
    "from src.preprocessing.video import normalize_path\n",
    "from src.post_processing.utils import read_json, joint_event, concat_videos\n",
    "from typing import List\n",
    "\n",
    "inferencing =TimeSformerInferencing(\n",
    "    num_frames= 30,\n",
    "    num_classes = 17,\n",
    "    game_name = './tv360/video_classification/gir_vs_feynord',\n",
    "    image_extractor=\"fcakyon/timesformer-large-finetuned-k400\",\n",
    "    checkpoint = './ckpt/ds_tv360_model_timesformer_nepochs_2_nframes_30.pth')\n",
    "\n",
    "results = inferencing.run(method='from_middle', spacing = 30)\n",
    "game, event2timestamp = process_football_events(json_path = results, rank = cfg.rank)\n",
    "#2m388"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "game, event2timestamp = process_football_events(json_path = results, rank = cfg.rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 23)\n",
      "Đã nối video thành công: Goal_22_23.mp4\n",
      "(35, 36)\n",
      "Đã nối video thành công: Goal_35_36.mp4\n",
      "(50, 51)\n",
      "Đã nối video thành công: Goal_50_51.mp4\n",
      "(68, 69)\n",
      "Đã nối video thành công: Goal_68_69.mp4\n",
      "(75, 76)\n",
      "Đã nối video thành công: Goal_75_76.mp4\n",
      "(80, 81)\n",
      "Đã nối video thành công: Goal_80_81.mp4\n",
      "(88, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:01<00:07,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã nối video thành công: Goal_88_89.mp4\n",
      "(97, 98)\n",
      "Đã nối video thành công: Goal_97_98.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "Đã nối video thành công: Cards_62.mp4\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:01<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã nối video thành công: Foul_5.mp4\n",
      "25\n",
      "Đã nối video thành công: Foul_25.mp4\n",
      "(24, 26)\n",
      "Đã nối video thành công: Substitution_24_26.mp4\n",
      "(77, 78)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:02<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã nối video thành công: Substitution_77_78.mp4\n",
      "9\n",
      "Đã nối video thành công: Shots_9.mp4\n",
      "(17, 18)\n",
      "Đã nối video thành công: Shots_17_18.mp4\n",
      "46\n",
      "Đã nối video thành công: Shots_46.mp4\n",
      "67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã nối video thành công: Shots_67.mp4\n",
      "79\n",
      "Đã nối video thành công: Shots_79.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"D:\\\\projects\\\\v2v\\\\v5\\\\tv360\\\\video_classification\"\n",
    "def merge_events(base_dir, game):\n",
    "    # basedir = \"F:/video_classification\"\n",
    "    game_path = f\"{base_dir}/{game}\"\n",
    "    highlights = []\n",
    "    for event, timestamps in tqdm(event2timestamp.items()):\n",
    "        for timestamp in timestamps:\n",
    "            print(timestamp)\n",
    "            if isinstance(timestamp, tuple):\n",
    "                # /visual/*mp4\n",
    "                video1 = normalize_path(glob.glob(f\"{game_path}/chunk_{timestamp[0]}/*.mp4\")[0])\n",
    "                video2 =  normalize_path(glob.glob(f\"{game_path}/chunk_{timestamp[1]}/*.mp4\")[0])\n",
    "                concat_videos([video1, video2], f\"{event}_{timestamp[0]}_{timestamp[1]}.mp4\")\n",
    "                highlights.append(f\"{event}_{timestamp[0]}_{timestamp[1]}.mp4\")\n",
    "            elif isinstance(timestamp, int):\n",
    "                video = normalize_path(glob.glob(f\"{game_path}/chunk_{timestamp}/*.mp4\")[0])\n",
    "                concat_videos([video], f\"{event}_{timestamp}.mp4\")\n",
    "                highlights.append(f\"{event}_{timestamp}.mp4\")\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    highlights = sorted(highlights, key=lambda x: list(map(int, re.findall(r'\\d+', x)))[0])\n",
    "    target_folder = \"sample\"\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "    for file in highlights:\n",
    "        if os.path.exists(file):  # Ensure the file exists before moving\n",
    "            shutil.move(file, os.path.join(target_folder, file))\n",
    "    \n",
    "    \n",
    "    return highlights\n",
    "\n",
    "highlights=merge_events(base_dir = base_dir, game = game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626\n",
      "735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/18 [02:18<39:11, 138.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 680 nằm ở giữa video (frame 504-1296), giữ nguyên video. Kết quả: sample\\Cards_62_full.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/18 [02:48<47:40, 168.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m tqdm(filelist):\n\u001b[0;32m     15\u001b[0m     videodata \u001b[38;5;241m=\u001b[39m skvideo\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mvread(filename)\n\u001b[1;32m---> 16\u001b[0m     scene_lum_idx \u001b[38;5;241m=\u001b[39m \u001b[43mskvideo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscenedet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideodata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhistogram\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameter1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     frame_cut \u001b[38;5;241m=\u001b[39m filter_highlight_scenes(scene_lum_idx)\n\u001b[0;32m     19\u001b[0m     cut_video_by_frame(video_path \u001b[38;5;241m=\u001b[39m filename, frame_position \u001b[38;5;241m=\u001b[39m frame_cut, middle_threshold\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.22\u001b[39m)\n",
      "File \u001b[1;32md:\\projects\\v2v\\v5\\.conda\\lib\\site-packages\\skvideo\\measure\\scene.py:147\u001b[0m, in \u001b[0;36mscenedet\u001b[1;34m(videodata, method, parameter1, min_scene_length)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parameter1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         parameter1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m--> 147\u001b[0m     detected_scenes \u001b[38;5;241m=\u001b[39m \u001b[43m_scenedet_histogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideodata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameter1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_scene_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medges\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parameter1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\projects\\v2v\\v5\\.conda\\lib\\site-packages\\skvideo\\measure\\scene.py:68\u001b[0m, in \u001b[0;36m_scenedet_histogram\u001b[1;34m(videodata, parameter1, min_scene_len)\u001b[0m\n\u001b[0;32m     66\u001b[0m curr \u001b[38;5;241m=\u001b[39m curr[\u001b[38;5;241m0\u001b[39m, :, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     67\u001b[0m nxt \u001b[38;5;241m=\u001b[39m nxt[\u001b[38;5;241m0\u001b[39m, :, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 68\u001b[0m hist1, bins \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m hist2, bins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(nxt, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m))\n\u001b[0;32m     71\u001b[0m hist1 \u001b[38;5;241m=\u001b[39m hist1\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32md:\\projects\\v2v\\v5\\.conda\\lib\\site-packages\\numpy\\lib\\_histograms_impl.py:858\u001b[0m, in \u001b[0;36mhistogram\u001b[1;34m(a, bins, range, density, weights)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# Compute the bin indices, and for values that lie exactly on\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# last_edge we need to subtract one\u001b[39;00m\n\u001b[0;32m    856\u001b[0m f_indices \u001b[38;5;241m=\u001b[39m ((_unsigned_subtract(tmp_a, first_edge) \u001b[38;5;241m/\u001b[39m norm_denom)\n\u001b[0;32m    857\u001b[0m              \u001b[38;5;241m*\u001b[39m norm_numerator)\n\u001b[1;32m--> 858\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[43mf_indices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m indices[indices \u001b[38;5;241m==\u001b[39m n_equal_bins] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;66;03m# The index computation is not guaranteed to give exactly\u001b[39;00m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;66;03m# consistent results within ~1 ULP of the bin edges.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import skvideo.measure\n",
    "import cv2\n",
    "import skvideo.io\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from src.post_processing.utils import filter_highlight_scenes, cut_video_by_frame, merge_videos\n",
    "np.float = float    \n",
    "np.int = int   #module 'numpy' has no attribute 'int'\n",
    "np.object = object    #module 'numpy' has no attribute 'object'\n",
    "np.bool = bool \n",
    "\n",
    "filelist = [f\"sample/{i}\" for i in os.listdir(\"sample\")]\n",
    "for filename in tqdm(filelist):\n",
    "    videodata = skvideo.io.vread(filename)\n",
    "    scene_lum_idx = skvideo.measure.scenedet(videodata, method='histogram', parameter1=1.0)\n",
    "    frame_cut = filter_highlight_scenes(scene_lum_idx)\n",
    "    cut_video_by_frame(video_path = filename, frame_position = frame_cut, middle_threshold= 0.22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ghép nối sử dụng phương pháp concat (nhanh, giữ nguyên chất lượng)\n",
    "merged_video = merge_videos(highlights, \"output_merged.mp4\", method=\"concat\")\n",
    "\n",
    "# Nếu có lỗi với phương pháp concat (ví dụ: codec khác nhau), thử phương pháp filter_complex\n",
    "if not merged_video:\n",
    "    merge_videos(highlights, \"output_merged.mp4\", method=\"filter_complex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
